{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "For this analysis, we will utilize the \"king County Housing Price from May 2014- May 2015\" created by the Center for Spatial Data Science. It contains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as metrics\n",
    "from random import gauss\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats as stats\n",
    "from sklearn.feature_selection import RFE\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore pairplot and graph warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('data/kc_house_data.csv')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: We have several columns with categorical values\n",
    "- waterfront      \n",
    "- view             \n",
    "- condition       \n",
    "- grade          \n",
    "- floors \n",
    "- zipcode\n",
    "\n",
    "Also the column sqft_basement is an object. Let's find out why.\n",
    "\n",
    "We have several null values in the waterfont and yr_renovated categories. we have a small number of null values in the view category. Yr_renovated seems self-explanatory - a nan value means that the\n",
    "house was not renovated. Let's explore the remaining two categories. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation \n",
    "\n",
    "- figuring out how to replace null values in columns\n",
    "- investigating duplicate id\n",
    "- creating null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#housing['date'] =  pd.to_datetime(housing['date'])\n",
    "#housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idcheck1 = housing[housing['id'] == 795000620]\n",
    "idcheck1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idcheck2 = housing[housing['id'] == 1825069031]\n",
    "idcheck2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing['waterfront'].isna().sum())\n",
    "housing['waterfront'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[(housing['waterfront'].isna()) & (housing['view'] == \"NONE\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['waterfront'].fillna(value='NO', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Waterfront view**\n",
    "\n",
    "- the only options are yes or no. \n",
    "Any property on a waterfront will have a value other than NONE in the view column. Since there are 2110 rows that have a NaN value in waterfront and a none value in the view column in our data, it seems safer to assume NO as the default for waterfront.\n",
    "\n",
    "We can either assume a property with a nan value for waterfront means it is not on the waterfront and replace all the nan values with no, or we can just drop the rows with a nan response. \n",
    "Since our data comprises of ~21,600 different rows, if we dropped these 2376 rows, we'd be loosing \n",
    "more than 10% of our data. \n",
    "\n",
    "So let's keep them and assume a nan response means no waterfront view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#454 columns with ? for a value. \n",
    "housing['sqft_basement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column sqrt_basement2 which is sqrt_living - sqrt-above. Addresses sqft_basement ? values.\n",
    "housing['sqft_basement2'] = housing['sqft_living'] - housing['sqft_above']\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has 3842 nan values, also has some 0.0 values\n",
    "print(housing['yr_renovated'].isna().sum())\n",
    "housing['yr_renovated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new column was_renovated. Assuming Nan value and 0.0 - means home was not renovated.\n",
    "housing['yr_renovated'].fillna(0, inplace=True)\n",
    "housing['was_renovated'] = housing['yr_renovated'] != 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing 0.0 in yr_renovated column with associated value in yr_built\n",
    "housing.loc[housing['yr_renovated'] == 0, ['yr_renovated']] = housing['yr_built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking dataframe\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing['view'].isna().sum())\n",
    "housing['view'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['view'].fillna(value='NONE', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View**\n",
    "\n",
    "- several options - none, nan, good, excellent, average, and fair.\n",
    "\n",
    "We can either assume a nan response means no view and replace all the nan values with none, \n",
    "or we can just drop the rows with a nan response.  \n",
    "Since our data comprises of ~21,600 different rows, if we dropped these 63 rows, \n",
    "we'd only be loosing 0.3% of our data.\n",
    "\n",
    "Let's keep them and assume a nan response means no view.\n",
    "\n",
    "**Sqft_basement**\n",
    "- created new column to address the '?' values and the 0.0 values.\n",
    "\n",
    "**Yr_renovated**\n",
    "- created new column that addresses the 0.0 values and the nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigating outlier bedrooms\n",
    "housing[housing['bedrooms'] > 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing 33 bedrooms with 3. we feel confident in assuming this was a typo based on the bathrooms and sqft_living\n",
    "housing['bedrooms'] = housing['bedrooms'].replace(33, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##exporting cleaned data frame\n",
    "housing.to_csv('./data/kc_house_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis\n",
    "Let's further explore some of our variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![housing_location](./images/housing_location.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![housing_location](./images/housing_location.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using QGIS import create distance from waterbody column.\n",
    "cleaned_housing = pd.read_csv('data/kc_water_dist_homes.csv')\n",
    "cleaned_housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min = cleaned_housing['price'].min()\n",
    "max = cleaned_housing['price'].max()\n",
    "mean = cleaned_housing['price'].mean()\n",
    "\n",
    "print (f\"The sale price range of homes sold is {min} to {max}\")\n",
    "print (f\"The mean sale price of homes was {mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(cleaned_housing['price']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = cleaned_housing['price']\n",
    "fig, ax = plt.subplots(2, 1, figsize = (9,12))\n",
    "\n",
    "# Plot the histogram   \n",
    "ax[0].hist(label, bins=100)\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[0].axvline(label.mean(), color='magenta', linestyle='dashed', linewidth=4)\n",
    "ax[0].axvline(label.median(), color='cyan', linestyle='dashed', linewidth=4)\n",
    "\n",
    "# Plot the boxplot   \n",
    "ax[1].boxplot(label, vert=False)\n",
    "ax[1].set_xlabel('price')\n",
    "fig.suptitle('Price Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Skewness =', stats.skew(cleaned_housing['price']))\n",
    "print ('Kurtosis =', stats.kurtosis(cleaned_housing['price']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- price is normally distributed but has a significant right tail skew.\n",
    "- Since the peak of the distribution is to the left of our mean, price is positively skewed.    \n",
    "- This means that more than half of the houses in our dataset sold for less than the average price $540,000. \n",
    "- Our kurtosis and skew are high - we expect to see a positive skew and tail.\n",
    "- Looking at our box plot - this illustrates that clearly - we have a number of outliers that sold for \n",
    "  significantly more than our average.\n",
    "- Moving forward, let's remove some of our highest priced homes. Let's focus on homes that sold for less than           1,500,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_housing.drop(cleaned_housing[ cleaned_housing['price'] >= 1500000 ].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot(cleaned_housing['price']);\n",
    "\n",
    "label = cleaned_housing['price']\n",
    "fig, ax = plt.subplots(2, 1, figsize = (9,12))\n",
    "\n",
    "# Plot the histogram   \n",
    "ax[0].hist(label, bins=100)\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[0].axvline(label.mean(), color='magenta', linestyle='dashed', linewidth=4)\n",
    "ax[0].axvline(label.median(), color='cyan', linestyle='dashed', linewidth=4)\n",
    "\n",
    "# Plot the boxplot   \n",
    "ax[1].boxplot(label, vert=False)\n",
    "ax[1].set_xlabel('price')\n",
    "fig.suptitle('Price Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating new column ratios to adjust for multicollinearity between two independent variables\n",
    "cleaned_housing['bed_bath_ratio'] = (cleaned_housing['bedrooms'] /  cleaned_housing['bathrooms'])\n",
    "cleaned_housing['sqft_living_to_bedroom_ratio'] = (cleaned_housing['sqft_living'] /  cleaned_housing['bedrooms'])\n",
    "cleaned_housing['sqft_living_to_bathroom_ratio'] = (cleaned_housing['sqft_living'] /  cleaned_housing['bathrooms'])\n",
    "cleaned_housing['ratio_sqft_lot_living'] = (cleaned_housing['sqft_lot'] /  cleaned_housing['sqft_living'])\n",
    "cleaned_housing['ratio_sqft_living_lot'] = (cleaned_housing['sqft_living'] /  cleaned_housing['sqft_lot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_housing['date'] =  pd.to_datetime(cleaned_housing['date'])\n",
    "\n",
    "#cleaned_housing['date'] =  cleaned_housing['date'].astype(str)\n",
    "\n",
    "#cleaned_housing['date'] = cleaned_housing['date'].dt.strftime('%d/%m/%Y')\n",
    "#cleaned_housing['date'] = pd.to_datetime(cleaned_housing['date'], format='%Y/%m/%d')\n",
    "#cleaned_housing['date'] = pd.to_datetime(cleaned_housing['date'], format='%m/%d/%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_housing['age_at_sale'] = (cleaned_housing['date'].str[4:].astype(int) - cleaned_housing['yr_built']).astype(int)\n",
    "\n",
    "#cleaned_housing['age_renovation_at_sale'] = (cleaned_housing['date'].str[4:].astype(int) - cleaned_housing['yr_renovated']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_housing.rename(columns = {'Hub distance_HubDist':'Distance_to_Water'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_housing = cleaned_housing.drop(['field_1'], axis=1)\n",
    "cleaned_housing = cleaned_housing.drop(['sqft_basement'], axis=1)\n",
    "cleaned_housing['zipcode'] = cleaned_housing['zipcode'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_housing['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up train test split\n",
    "X = cleaned_housing.drop('price', axis=1)\n",
    "y = cleaned_housing['price']\n",
    "\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining X_train and y_train to get train_df\n",
    "train_df = pd.concat([y_train, X_train], axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_housing.corr().price.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.triu(np.ones_like(cleaned_housing.corr(), dtype=bool))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "cor = cleaned_housing.corr().abs()\n",
    "sns.heatmap(cor, mask=mask, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1 - Simple Regression 1\n",
    "simple_formula = 'price ~ sqft_living'\n",
    "simple_model = sm.formula.ols(formula=simple_formula, data=train_df)\n",
    "simple_model.summary = simple_model.fit().summary()\n",
    "\n",
    "simple_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(simple_model.resid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = simple_model.resid\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(15, 5))\n",
    "ax[0].scatter(x=simple_model.fittedvalues,y=resid_simple_model)\n",
    "ax[0].set_xlabel(\"Predicted Values\")\n",
    "ax[0].set_ylabel(\"Residual Error\")\n",
    "ax[0].set_title(label=\"Test for Homoscedasticity\")\n",
    "\n",
    "\n",
    "ax[1].hist(simple_model)\n",
    "ax[1].set_xlabel(\"Residual Error\")\n",
    "ax[1].set_ylabel(\"Count\")\n",
    "ax[1].set_title(label=\"Histogram of Residual Error\");\n",
    "\n",
    "import statsmodels.api as sm\n",
    "plt.style.use('ggplot')\n",
    "fig = sm.graphics.qqplot(simple_model, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max = y.max()\n",
    "y_min = y.min()\n",
    "\n",
    "ax = sns.scatterplot(X=simple_model.fittedvalues, y=y)\n",
    "ax.set(ylim=(y_min, y_max))\n",
    "ax.set(xlim=(y_min, y_max))\n",
    "ax.set_xlabel(\"Predicted Sale Price\")\n",
    "ax.set_ylabel(\"Actual Sale Price\")\n",
    "\n",
    "X_ref = y_ref = np.linspace(y_min, y_max, 100)\n",
    "plt.plot(X_ref, y_ref, color='red', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_model_1_train_preds = simple_model.predict(sm.add_constant(X_train['sqft_living']))\n",
    "#simple_model_1_train_preds\n",
    "simple_train_preds = simple_model.predict(X_train['sqft_living'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot our points, rating vs balance, as a scatterplot\n",
    "plt.scatter(train_df['sqft_living'], train_df['price'])\n",
    "\n",
    "# Plot the line of best fit!\n",
    "plt.plot(train_df['sqft_living'], simple_train_preds, color='black')\n",
    "\n",
    "plt.ylabel('Home Sale Price')\n",
    "plt.xlabel('Sqft_living')\n",
    "plt.title('Relationship between Home Sale Price and Sqft living space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One last thing - can visualize both train and test set!\n",
    "\n",
    "# Plot our training data\n",
    "plt.scatter(train_df['Rating'], train_df['Balance'], color='blue', label='Training')\n",
    "# Plot our testing data\n",
    "plt.scatter(test_df['Rating'], test_df['Balance'], color='green', label='Testing')\n",
    "\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(train_df['Rating'], simple_train_preds, color='black')\n",
    "# Plotting for the test data just to show it's the same!\n",
    "plt.plot(test_df['Rating'], simple_test_preds, color='red')\n",
    "\n",
    "plt.ylabel('Credit Card Balance')\n",
    "plt.xlabel('Credit Rating')\n",
    "plt.title('Relationship between Credit Rating and Credit Card Balance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ResidualsPlot(model, hist=False, qqplot=True)\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- y = 198.74 * ('sqft') - 99,610. \n",
    "- Sqft_living accounts for about 43.6% of the variance in our sale price\n",
    "- Each unit increase of Sqft_living increases the selling price of homes by on average about $200.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2 - Simple Regression 2\n",
    "simple_formula_2 = 'price ~ sqft_living15'\n",
    "simple_model_2 = sm.formula.ols(formula=simple_formula_2, data=train_df)\n",
    "simple_model_2summary = simple_model_2.fit().summary()\n",
    "\n",
    "simple_model_2summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##input assumption visuals ## y_scaled= np.log(y)??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- y = 225.16 * ('sqft') - 60,800. \n",
    "- the square footage living space for the nearest 15 homes account for 35% of the variance in our sale price\n",
    "- Each unit increase of Sqft_living15 increases the selling price of homes on average by about $225.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [c for c in train_df.columns if train_df[c].dtype == 'O']\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an encoder object. This will help us to convert categorical variables to new columns\n",
    "encoder = OneHotEncoder(handle_unknown='error',\n",
    "                        drop='first', \n",
    "                        categories='auto')\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('ohe', encoder, cat_cols)],\n",
    "                       remainder='passthrough')\n",
    "ct.fit(X_train) \n",
    "X_train_enc = ct.transform(X_train)\n",
    "X_test_enc = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variables for the \"condition\" column\n",
    "condition_dummies = pd.get_dummies(X_train_condition['condition'], drop_first=True)\n",
    "condition_dummies\n",
    "#drops 'Average', creates 4 additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummies = pd.concat([X_train_condition, condition_dummies], axis=1)\n",
    "X_train_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3 - Multiple Regression 1\n",
    "Multiple_formula = 'price ~ sqft_living + yr_built + Distance_to_Water + bed_bath_ratio'\n",
    "Multiple_model = sm.formula.ols(formula=Multiple_formula, data=train_df)\n",
    "Multiple_model_summary = Multiple_model.fit().summary()\n",
    "\n",
    "Multiple_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3 - Multiple Regression 2\n",
    "#add in condition and zip code\n",
    "Multiple_formula_2 = 'price ~ sqft_living + yr_built + Distance_to_Water + bed_bath_ratio'\n",
    "Multiple_model_2 = sm.formula.ols(formula=Multiple_formula_2, data=train_df)\n",
    "Multiple_model_2summary = Multiple_model_2.fit().summary()\n",
    "\n",
    "Multiple_model_2summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(housing)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rfe = LinearRegression()\n",
    "select = RFE(lr_rfe, n_features_to_select =4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(cleaned_housing.drop('price', axis=1))\n",
    "cleaned_housing_scaled = ss.transform(cleaned_housing.drop('price', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_housing_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select.fit(X=cleaned_housing_scaled, y=cleaned_housing['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use sqft_living  yr_built  sqft_living15  sqft_lot15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Polynomials using all except categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_housing.drop('price', axis=1)\n",
    "y = cleaned_housing['price']\n",
    "pf = PolynomialFeatures(degree=3)\n",
    "pf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_df = pd.DataFrame(pf.transform(X), columns= pf.get_feature_names() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(polynomial_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(polynomial_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT RUN CELL BELOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
